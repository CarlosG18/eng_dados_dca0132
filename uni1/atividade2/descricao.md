# ğŸ—‚ï¸ Atividade 2 - Programando MapReduce em Hadoop

A atividade consiste na programaÃ§Ã£o de funÃ§Ãµes **Map** e **Reduce** para processamento de dados em um cluster **Hadoop**, utilizando datasets reais.

## ğŸ§° Estrutura da Atividade

A prÃ¡tica estÃ¡ dividida em duas tarefas principais, cada uma com objetivos especÃ­ficos:

* **Tarefa 1 â€“ Contagem de Palavras**: Conta a quantidade de ocorrÃªncias de cada palavra em um arquivo de texto.
* **Tarefa 2 â€“ Acessos por IP**: Analisa um log de servidor HTTP para contabilizar acessos por endereÃ§o IP.

Ambas as tarefas utilizam scripts Python (`mapper.py` e `reducer.py`) customizados e sÃ£o executadas em um ambiente Hadoop.

## ğŸ“ ConteÃºdo do RepositÃ³rio

* `mapper_tarefa1.py` â€“ Script de mapeamento para a contagem de palavras.
* `reducer_tarefa1.py` â€“ Script de reduÃ§Ã£o para a contagem de palavras.
* `mapper_tarefa2.py` â€“ Script de mapeamento para anÃ¡lise de acessos por IP.
* `reducer_tarefa2.py` â€“ Script de reduÃ§Ã£o para anÃ¡lise de acessos por IP.
* `README.md` â€“ InstruÃ§Ãµes e detalhes da atividade.

## ğŸ“š Recursos Utilizados

* ğŸ“‚ **CÃ³digo base para inÃ­cio da prÃ¡tica:**
  [Scripts iniciais](https://www.dca.ufrn.br/~viegas/disciplinas/DCA0132/files/Scripts/)

* ğŸ“„ **Datasets utilizados:**
  [https://goo.gl/A3MhFS](https://goo.gl/A3MhFS)

## ğŸ“ DescriÃ§Ã£o das Tarefas

### 1. ğŸ“Š Contagem de Palavras

* **Arquivo:** `texto.txt` (6,5MB)
* **Requisitos:**

  * A saÃ­da deve conter: `palavra<TAB>quantidade`
  * A contagem deve ser **case-insensitive** (ex: "Casa" = "casa")
  * A saÃ­da deve estar em **ordem decrescente de frequÃªncia**

### 2. ğŸŒ Acessos por IP

* **Arquivo:** `access.log.new` (244MB)
* **Requisitos:**

  * A saÃ­da deve conter: `IP<TAB>quantidade de acessos`
  * Apenas o endereÃ§o IP de cada linha do log deve ser considerado
  * A saÃ­da final deve estar em **ordem decrescente de acessos**

## â–¶ï¸ Como Executar no Hadoop
 > Os arquivos bases `texto.txt` e `access.log.new` deve esta no volume **my_files** alÃ©m do script mapper e reduce, devem esta dentro do container do hadoop-master.

1. **Subir arquivos para o HDFS:**

   ```bash
   hdfs dfs -put texto.txt
   hdfs dfs -put access.log.new
   ```

2. **Executar a tarefa 1 no cluster:**

   ```bash
   yarn jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming*.jar -files mapper_tarefa1.py,reducer_tarefa1.py -mapper "python mapper_tarefa1.py" -reducer "python reducer_tarefa1.py" -input access.log.new -output output-ip
   ```

3. **Executar a tarefa 2 no cluster:**

   ```bash
   yarn jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming*.jar -files mapper_tarefa2.py,reducer_tarefa2.py -mapper "python mapper_tarefa2.py" -reducer "python reducer_tarefa2.py" -input access.log.new -output output-ip
   ```

4. **Visualizar o resultado:**

   ```bash
   hdfs dfs -cat <saida que voce colocou>/*
   ```
