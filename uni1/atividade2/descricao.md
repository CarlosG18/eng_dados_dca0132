# ğŸ—‚ï¸ Atividade 2 - Programando MapReduce em Hadoop

A atividade consiste na programaÃ§Ã£o de funÃ§Ãµes **Map** e **Reduce** para processamento de dados em um cluster **Hadoop**, utilizando datasets reais.

## ğŸ§° Estrutura da Atividade

A prÃ¡tica estÃ¡ dividida em duas tarefas principais, cada uma com objetivos especÃ­ficos:

* **Tarefa 1 â€“ Contagem de Palavras**: Conta a quantidade de ocorrÃªncias de cada palavra em um arquivo de texto.
* **Tarefa 2 â€“ Acessos por IP**: Analisa um log de servidor HTTP para contabilizar acessos por endereÃ§o IP.

Ambas as tarefas utilizam scripts Python (`mapper.py` e `reducer.py`) customizados e sÃ£o executadas em um ambiente Hadoop.

## ğŸ“ ConteÃºdo do RepositÃ³rio

* `mapper_tarefa1.py` â€“ Script de mapeamento para a contagem de palavras.
* `reducer_tarefa1.py` â€“ Script de reduÃ§Ã£o para a contagem de palavras.
* `mapper_tarefa2.py` â€“ Script de mapeamento para anÃ¡lise de acessos por IP.
* `reducer_tarefa2.py` â€“ Script de reduÃ§Ã£o para anÃ¡lise de acessos por IP.
* `README.md` â€“ InstruÃ§Ãµes e detalhes da atividade.

## ğŸ“š Recursos Utilizados

* ğŸ“‚ **CÃ³digo base para inÃ­cio da prÃ¡tica:**
  [Scripts iniciais](https://www.dca.ufrn.br/~viegas/disciplinas/DCA0132/files/Scripts/)

* ğŸ“„ **Datasets utilizados:**
  [https://goo.gl/A3MhFS](https://goo.gl/A3MhFS)

## ğŸ“ DescriÃ§Ã£o das Tarefas

### 1. ğŸ“Š Contagem de Palavras

* **Arquivo:** `texto.txt` (6,5MB)
* **Requisitos:**

  * A saÃ­da deve conter: `palavra<TAB>quantidade`
  * A contagem deve ser **case-insensitive** (ex: "Casa" = "casa")
  * A saÃ­da deve estar em **ordem decrescente de frequÃªncia**

### 2. ğŸŒ Acessos por IP

* **Arquivo:** `access.log.new` (244MB)
* **Requisitos:**

  * A saÃ­da deve conter: `IP<TAB>quantidade de acessos`
  * Apenas o endereÃ§o IP de cada linha do log deve ser considerado
  * A saÃ­da final deve estar em **ordem decrescente de acessos**

## â–¶ï¸ Como Executar no Hadoop

1. **Subir arquivos para o HDFS:**

   ```bash
   hdfs dfs -put texto.txt /user/seu_usuario/
   hdfs dfs -put access.log.new /user/seu_usuario/
   ```

2. **Executar a tarefa no cluster:**

   ```bash
   hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
     -input /user/seu_usuario/texto.txt \
     -output /user/seu_usuario/saida_tarefa1 \
     -mapper mapper_tarefa1.py \
     -reducer reducer_tarefa1.py \
     -file mapper_tarefa1.py \
     -file reducer_tarefa1.py
   ```

   *(Adapte os caminhos para a Tarefa 2 conforme necessÃ¡rio.)*

3. **Visualizar o resultado:**

   ```bash
   hdfs dfs -cat /user/seu_usuario/saida_tarefa1/part-00000
   ```
